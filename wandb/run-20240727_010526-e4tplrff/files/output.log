Total Epochs: 3000, Total Iters: 1149000
Iters Per Epoch, Training: 0383, Validation: 023
pose=======+>pose.shape: torch.Size([3, 196, 263])
inp.size(0)====>tensor([], device='cuda:0', size=(0, 3), dtype=torch.int64)
/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.
  warnings.warn("Setting attributes on ParameterList is not supported.")
motion motion_ids ========================+> tensor([[ 895,  932,  364,  746,  212,  144,  602, 1019,   62,  231,  415,  588,
          755,  697,  664,  987,  916,  952,   79,  870,  573,  977,  508,  989,
          966,  249,  945,  980,  724,  462,  811,  268,  873,  732, 1005,  817,
          726,  689,  986,  337,  378,  156,  146,  683,  427,  137,  593,  599,
          931,  334,  477,  731,  949,  756,  965,  559,  808,   99,  433,  469,
          388,   76,  224,  599,  112,  730,  940,  922,  917,  856,  831,  134,
          642,   20,  642,  995,  763,  531,  109,  192,  642,  615,  961,  108,
           15,  514, 1018,  366,  955,  439,  174,  835,  205, 1016,  541,  660,
           26,  892,  732,  163,   24,  125,  723,  271,  437,  111,  749,  780,
          542,  393,  976,  429,  134,  967,  347,  171,  340,  833,  580,  835,
          899,  251,   48,  498,  222,  358,   91,  607,  398,  742,  170,   99,
           99,  749,  397,  310, 1023,  920,  642,  998,  557,  155,  984,  755,
          485,  909,  909,  863,    8,  294,  457,  412,  339,  325,  899,  453,
          568,  548,  540,  133,  676,  633, 1019,  465,    3,  649,  507,  946,
          212,  715,  813,  498,  498,  101,  695, 1024,  590,  134,   17,  592,
          887,  211,   98,  315,  876,  888,  544,  628,  944,  511,  648,  533,
          917,  633,  956,  859],
        [  19,  144,  410,  366,  866,  212,  406,   44,  390,  850,  350,  751,
          925,  886,  277,   91,  280,  414,  799,  498,   10,  926,  941,  155,
          365,  856,  560,  635,  760,  661,  882,  383,  264,  821,  818,  570,
          373,  978,  614,  597,  622,  970,  658,  410,  920,  350,  191,  615,
          504, 1007,  779, 1008,   86,  386,  287,   35,  710,  346,  349,  441,
          704,  642,  311,  236,  226,  770,  755,  133,  226,  525,  292,  170,
          272,  760,  226,  811,  268,  987,  228,  815, 1024,  739,  908,  234,
          125,  557,  705,  666,  810,  958,  774,  741,  176,  864,  826,  621,
          824,  417,  209,  499,  289,  321,  219,  394,  546,   51,  619,  450,
          609,   62,  534,  987,  555,   50,  966,   29,  137,  359,  908,  254,
          542,  592,  574,  642,  682,  219,  175,  762,  220,  732,  499,  302,
           77,   76,  484,  870,  226,  555,  441,  831,   37,  133,  618,  430,
           50,  499,  175,  922,  334,  203,  898,  560,  174,   81,  191,  539,
          332,  138,  871,   62,  441,   68,  327,  314,  691,  704,  283,  947,
          928,  239,  200,  375,  929,  784,  795,  648,  345,  415,  780, 1004,
           46,  525,  388,   90,  653,  733,  127,  574,   53,  337,  597,  335,
          280,  917,  560,  267],
        [  77,  241,  858,  627,  103,  791,  932,  495,  403,  909,  452,   55,
          298,   30,  545,  729,  241,  875,  958, 1018,  309,  786,  731,  153,
          474,  724,  188,  887,  918,  681,  198,  635,  409,  992,  427,  505,
          379,  941,  650,  961,   23,  446,  484,  725,  172,   31,  564,  956,
          502,  247,  769,   60,  732,  719,  602, 1005,  532,  561,  924,  869,
          530,  229,  566,  627,  403,  992,  192,  108,  153,  674,  319,  938,
          590,  581,   51,  201,  155,  862,  405,   64,  861,   71,  244,  935,
           17,  811,  980,  288,  792, 1019,  192,  117,  909,  337,  626,  875,
          312,   15,  893,  899,  935,  914,  625,  305, 1002,  337,  511,  489,
          605,  236,  221,  465,  137,  737,  437,  166,   44,  534,  883,  112,
          899,  909,  432,  350,  789,  700,  334,  354,  179,  633,  317,  294,
          866,  656,  866,  694,  628,  390,  926,  987,  423,  441,  782,  923,
         1004,  833,  336,  376,  276,  392,  746,  414,  275,  265,  994,  972,
          960,  320, 1001, 1016,  104,  765,    3,  251,  118,  845,  272,  418,
          925,  238,   84,  182,  557,  627,  899,  107,  119,  259,  531,  521,
          692,  247,  353,  159,  292,  476,  358,  706,  350,  545,  223,  678,
         1007,  825,  628,  978]], device='cuda:0')
 labels====> tensor([[372, 147, 184, 653, 253, 263, 565, 565, 275, 348, 348,  71, 209, 690,
         690, 690, 648, 604, 604, 277, 238, 814, 814, 633, 633, 633, 633, 635,
         635, 565, 672, 565, 615, 275, 348, 348, 777, 348, 209, 777, 777, 690,
         648, 648, 277, 277, 277, 648, 603, 231, 223, 653, 653, 653, 347, 710,
         710, 309, 309, 309, 309, 309, 309, 309, 309, 620, 253, 253, 253, 253,
         620, 463, 463, 726, 691, 691, 726, 726,  29,  36,  36,  36,  36, 237,
         237, 849, 630,  37, 419, 703, 703, 985, 117, 468, 407, 517, 283, 626,
         806, 806, 806, 806, 804, 806, 806, 630, 517, 517, 849, 517, 143, 703,
         703, 985, 985, 703, 630, 407, 626, 201, 201, 806, 684, 684, 684, 806,
         916, 916, 517,  37,  37, 517, 419,  59,  29, 710, 710, 730, 704, 463,
         184, 184, 309, 309, 309, 253, 507, 263, 605, 253, 209, 209,  71,  71,
         874, 286, 309, 710, 710, 726, 463, 264, 884, 884, 767, 767, 761, 761,
         959, 613, 613, 613, 767, 463, 117, 985, 985, 629, 629, 255, 463, 184,
         184, 184, 184, 184, 184, 620, 253, 999, 999, 999, 999, 999, 286, 463],
        [539, 539, 539, 886, 886, 886, 886, 886, 539, 539, 886, 886, 886, 886,
         205, 722, 539, 886, 886, 886, 886, 886, 886, 722, 886, 886, 886, 886,
         886, 886, 886, 886, 205, 886, 886, 886, 886, 862, 886, 886, 886, 886,
         886, 886, 691, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996],
        [735,  64, 463, 463, 874, 874, 286, 874, 463, 613, 813, 813, 813,   0,
           0, 512, 512, 512, 546, 959, 484, 484,  30,  30, 610, 380, 610, 380,
         797, 797, 797, 797, 797, 959, 546, 484, 329, 967, 505, 505, 512, 512,
         512, 512, 675, 675, 915, 959, 116, 888, 116,  30, 116, 790, 790, 942,
         790, 942, 942, 942, 942, 942,  79,  79, 793, 793, 679, 679, 652, 679,
         696, 652, 652, 652, 652, 652, 655, 891, 655, 655, 655, 908, 908, 908,
         204, 204, 204, 204, 204, 204, 204, 204, 204, 282, 282, 282, 282, 815,
         845, 845, 845, 812, 812, 602, 658, 602, 742, 742, 645, 645, 645, 645,
         645, 543, 866, 866, 645, 658, 658, 329, 658, 812, 161, 812, 812, 812,
         812, 812, 812, 658, 658, 658,  30, 866, 352, 866, 543, 543, 352, 543,
         352, 543, 553, 976,  59, 985, 985, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996]],
       device='cuda:0')
Traceback (most recent call last):
  File "trainers/train_transformotion.py", line 150, in <module>
    trainer.train(train_loader, val_loader, eval_val_loader, eval_wrapper=eval_wrapper, plot_eval=plot_t2m)
  File "/root/Transformotion/trainers/../models/transformers/transformotion_trainer.py", line 153, in train
    plot_func=plot_eval, save_ckpt=False, save_anim=True
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 26, in decorate_context
    return func(*args, **kwargs)
  File "/root/Transformotion/trainers/../utils/eval_t2m.py", line 458, in evaluation_mask_transformer
    all_pred_motions = trans.generate(clip_text, m_length, motion_ids, temperature=1)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 26, in decorate_context
    return func(*args, **kwargs)
  File "/root/Transformotion/trainers/../models/transformers/tools.py", line 42, in inner
    out = fn(model, *args, **kwargs)
  File "/root/Transformotion/trainers/../models/transformers/transformotion.py", line 305, in generate
    pred_motions = self.vq_model.forward_decoder(motion_ids.unsqueeze(-1))
  File "/root/Transformotion/trainers/../models/vq/model.py", line 95, in forward_decoder
    x_out = self.decoder(x)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/Transformotion/trainers/../models/vq/encdec.py", line 67, in forward
    x = self.model(x)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/Transformotion/trainers/../models/vq/resnet.py", line 84, in forward
    return self.model(x)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/Transformotion/trainers/../models/vq/resnet.py", line 57, in forward
    x = self.conv1(x)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 259, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR
You can try to repro this exception using the following code snippet. If that doesn't trigger the error, please include your original repro script when reporting this issue.
import torch
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.benchmark = False
torch.backends.cudnn.deterministic = False
torch.backends.cudnn.allow_tf32 = True
data = torch.randn([3, 1024, 1, 196], dtype=torch.float, device='cuda', requires_grad=True)
net = torch.nn.Conv2d(1024, 1024, kernel_size=[1, 3], padding=[0, 1], stride=[1, 1], dilation=[1, 1], groups=1)
net = net.cuda().float()
out = net(data)
out.backward(torch.randn_like(out))
torch.cuda.synchronize()
ConvolutionParams
    data_type = CUDNN_DATA_FLOAT
    padding = [0, 1, 0]
    stride = [1, 1, 0]
    dilation = [1, 1, 0]
    groups = 1
    deterministic = false
    allow_tf32 = true
input: TensorDescriptor 0x5587fc9d6a60
    type = CUDNN_DATA_FLOAT
    nbDims = 4
    dimA = 3, 1024, 1, 196,
    strideA = 200704, 196, 196, 1,
output: TensorDescriptor 0x5587fc9d62e0
    type = CUDNN_DATA_FLOAT
    nbDims = 4
    dimA = 3, 1024, 1, 196,
    strideA = 200704, 196, 196, 1,
weight: FilterDescriptor 0x5587fca18620
    type = CUDNN_DATA_FLOAT
    tensor_format = CUDNN_TENSOR_NCHW
    nbDims = 4
    dimA = 1024, 1024, 1, 3,
Pointer addresses:
    input: 0x7ff0d5001000
    output: 0x7ff08c24c000
    weight: 0x7ff0dc600000
Forward algorithm: 5