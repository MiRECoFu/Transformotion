Load model epoch:21 iterations:8426
Total Epochs: 3000, Total Iters: 1149000
Iters Per Epoch, Training: 0383, Validation: 023
inp.size(0)====>tensor([], device='cuda:0', size=(0, 64), dtype=torch.int64)
logits==========+>torch.Size([1, 1, 1024])
pred_ids=======tensor([[909]], device='cuda:0'),
generated========tensor([], device='cuda:0', size=(64, 0), dtype=torch.int64)
logits==========+>torch.Size([1, 2, 1024])
pred_ids=======tensor([[909]], device='cuda:0'),
generated========tensor([[909]], device='cuda:0')
logits==========+>torch.Size([1, 3, 1024])
pred_ids=======tensor([[909]], device='cuda:0'),
generated========tensor([[909, 909]], device='cuda:0')
logits==========+>torch.Size([1, 4, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909]], device='cuda:0')
logits==========+>torch.Size([1, 5, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735]], device='cuda:0')
logits==========+>torch.Size([1, 6, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 7, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 8, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 9, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 10, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 11, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 12, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735]],
       device='cuda:0')
logits==========+>torch.Size([1, 13, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735]],
       device='cuda:0')
logits==========+>torch.Size([1, 14, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735]],
       device='cuda:0')
logits==========+>torch.Size([1, 15, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735]],
       device='cuda:0')
logits==========+>torch.Size([1, 16, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735,
         735]], device='cuda:0')
logits==========+>torch.Size([1, 17, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735,
         735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 18, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735,
         735, 735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 19, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735,
         735, 735, 735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 20, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735,
         735, 735, 735, 735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 21, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735,
         735, 735, 735, 735, 735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 22, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735,
         735, 735, 735, 735, 735, 735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 23, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735,
         735, 735, 735, 735, 735, 735, 735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 24, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735,
         735, 735, 735, 735, 735, 735, 735, 735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 25, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735,
         735, 735, 735, 735, 735, 735, 735, 735, 735, 735]], device='cuda:0')
logits==========+>torch.Size([1, 26, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735,
         735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735]],
       device='cuda:0')
logits==========+>torch.Size([1, 27, 1024])
pred_ids=======tensor([[735]], device='cuda:0'),
generated========tensor([[909, 909, 909, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735,
         735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735, 735]],
       device='cuda:0')
/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.
  warnings.warn("Setting attributes on ParameterList is not supported.")
Traceback (most recent call last):
  File "trainers/train_transformotion.py", line 150, in <module>
    trainer.train(train_loader, val_loader, eval_val_loader, eval_wrapper=eval_wrapper, plot_eval=plot_t2m)
  File "/root/Transformotion/trainers/../models/transformers/transformotion_trainer.py", line 153, in train
    plot_func=plot_eval, save_ckpt=False, save_anim=True
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 26, in decorate_context
    return func(*args, **kwargs)
  File "/root/Transformotion/trainers/../utils/eval_t2m.py", line 610, in evaluation_transformer
    pred_pose = trans.generate(clip_text[k:k+1], m_length, motion_ids[k:k+1])
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 26, in decorate_context
    return func(*args, **kwargs)
  File "/root/Transformotion/trainers/../models/transformers/tools.py", line 42, in inner
    out = fn(model, *args, **kwargs)
  File "/root/Transformotion/trainers/../models/transformers/transformotion.py", line 280, in generate
    logits, mems = self.forward(prompt_texts, generated, m_lens, labels=labels[:, k:k+1], mems=None, is_generating=True)
  File "/root/Transformotion/trainers/../models/transformers/transformotion.py", line 184, in forward
    prompt_logits = self.encode_text(prompt_texts)
  File "/root/Transformotion/trainers/../models/transformers/transformotion.py", line 165, in encode_text
    text = clip.tokenize(raw_text, truncate=True).to(device)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/clip/clip.py", line 230, in tokenize
    all_tokens = [[sot_token] + _tokenizer.encode(text) + [eot_token] for text in texts]
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/clip/clip.py", line 230, in <listcomp>
    all_tokens = [[sot_token] + _tokenizer.encode(text) + [eot_token] for text in texts]
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/clip/simple_tokenizer.py", line 123, in encode
    text = whitespace_clean(basic_clean(text)).lower()
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/clip/simple_tokenizer.py", line 51, in basic_clean
    text = ftfy.fix_text(text)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/ftfy/__init__.py", line 297, in fix_text
    config = _config_from_kwargs(config, kwargs)
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/ftfy/__init__.py", line 188, in _config_from_kwargs
    config = config._replace(**kwargs)
KeyboardInterrupt