Total Epochs: 3000, Total Iters: 1149000
Iters Per Epoch, Training: 0383, Validation: 023
inp.size(0)====>tensor([], device='cuda:0', size=(0, 3), dtype=torch.int64)
/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.
  warnings.warn("Setting attributes on ParameterList is not supported.")
motion motion_ids ========================+> tensor([[ 890,  918,  369,  719,  203,  136,  618, 1014,   80,  212,  412,  591,
          737,  696,  659,  987,  899,  951,   61,  884,  577,  992,  505,  991,
          959,  245,  935,  974,  729,  458,  821,  279,  899,  732, 1002,  823,
          710,  669,  982,  341,  378,  145,  144,  708,  405,  137,  576,  619,
          937,  310,  499,  730,  941,  733,  959,  553,  799,  109,  414,  448,
          388,   89,  247,  603,  101,  735,  941,  921,  929,  848,  839,  135,
          653,   14,  654,  996,  770,  545,  101,  167,  657,  637,  957,   99,
            9,  529, 1014,  381,  947,  461,  166,  831,  209, 1012,  520,  655,
           37,  883,  733,  137,   21,  101,  710,  291,  445,  102,  755,  755,
          518,  380,  968,  424,  133,  972,  360,  151,  343,  833,  580,  835,
          888,  264,   50,  507,  220,  359,   87,  617,  423,  760,  164,  107,
           99,  759,  385,  301, 1021,  899,  651,  995,  559,  145,  993,  748,
          466,  899,  905,  852,    6,  294,  455,  415,  322,  326,  899,  446,
          551,  537,  529,  122,  656,  628, 1020,  474,    4,  663,  509,  948,
          213,  705,  812,  528,  461,  101,  697]], device='cuda:0')
 labels====> tensor([[372, 147, 184, 653, 253, 263, 565, 565, 275, 348, 348,  71, 209, 690,
         690, 690, 648, 604, 604, 277, 238, 814, 814, 633, 633, 633, 633, 635,
         635, 565, 672, 565, 615, 275, 348, 348, 777, 348, 209, 777, 777, 690,
         648, 648, 277, 277, 277, 648, 603, 231, 223, 653, 653, 653, 347, 710,
         710, 309, 309, 309, 309, 309, 309, 309, 309, 620, 253, 253, 253, 253,
         620, 463, 463, 726, 691, 691, 726, 726,  29,  36,  36,  36,  36, 237,
         237, 849, 630,  37, 419, 703, 703, 985, 117, 468, 407, 517, 283, 626,
         806, 806, 806, 806, 804, 806, 806, 630, 517, 517, 849, 517, 143, 703,
         703, 985, 985, 703, 630, 407, 626, 201, 201, 806, 684, 684, 684, 806,
         916, 916, 517,  37,  37, 517, 419,  59,  29, 710, 710, 730, 704, 463,
         184, 184, 309, 309, 309, 253, 507, 263, 605, 253, 209, 209,  71,  71,
         874, 286, 309, 710, 710, 726, 463, 264, 884, 884, 767, 767, 761, 761,
         959, 613, 613, 613, 767, 463, 117, 985, 985, 629, 629, 255, 463, 184,
         184, 184, 184, 184, 184, 620, 253, 999, 999, 999, 999, 999, 286, 463]],
       device='cuda:0')
inp.size(0)====>tensor([], device='cuda:0', size=(0, 3), dtype=torch.int64)
motion motion_ids ========================+> tensor([[ 596,  130,   15,  604,  910,  183,  101,  314,  874,  880,  529,  637,
          940,  505,  651,  574,  893,  631,  979,  858,  989,  341, 1019,  545,
          849,  188,  719,  750,  638,  900,  552, 1004,  866,  378,   59,  199,
          690,  987,  204,  481, 1006,   70,  566,  651,  748,  592,  144,   99,
          337,  572,  223,  994,  438,  357,  230,  741,  666,  126,   57,  670,
          185,  939,  102,  770,  235,  867,  111, 1002,  952,  898,  298,  562,
          247,  104,  566,  844,  503,   99, 1010,  645,  786,  658,  677,  823,
          650,  206,  114,  507,  953,  773,  337,  827,  132,  884,   70,  274,
          441, 1008,   48,  320,  840,  737,  485,  789,  334,  299,  638,  714,
          200,   70,  767,  320,  835,  541,  495,  760,  826,  945,   39,  678,
          279,    7,  697,  656,   57,  658,  534,  446,  467, 1013,  155,  410,
          665,  955,  153,  231,  976,  171,  973,   29,  791,  201,  507,   27,
          556,  123,  884,  378,  147,   55,  150,  339,  644,  440,   58,  493,
          903,   50,  670, 1009,  711,    8,  898,  732,  698,  207,    6,   62,
          960,  326,  192,  225,  647,  259,  529,  136,  393,  892,  111,  440,
          543,  965,  170,  665,  687,   50,  631,  611,  238,  416,  968,  898,
          144,  688,  545,  157]], device='cuda:0')
 labels====> tensor([[539, 539, 539, 886, 886, 886, 886, 886, 539, 539, 886, 886, 886, 886,
         205, 722, 539, 886, 886, 886, 886, 886, 886, 722, 886, 886, 886, 886,
         886, 886, 886, 886, 205, 886, 886, 886, 886, 862, 886, 886, 886, 886,
         886, 886, 691, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996]],
       device='cuda:0')
inp.size(0)====>tensor([], device='cuda:0', size=(0, 3), dtype=torch.int64)
Traceback (most recent call last):
  File "trainers/train_transformotion.py", line 150, in <module>
    trainer.train(train_loader, val_loader, eval_val_loader, eval_wrapper=eval_wrapper, plot_eval=plot_t2m)
  File "/root/Transformotion/trainers/../models/transformers/transformotion_trainer.py", line 153, in train
    plot_func=plot_eval, save_ckpt=False, save_anim=True
  File "/root/miniconda3/envs/transformotion/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 26, in decorate_context
    return func(*args, **kwargs)
  File "/root/Transformotion/trainers/../utils/eval_t2m.py", line 676, in evaluation_transformer
    diversity_real = calculate_diversity(motion_annotation_np, 300 if nb_sample > 300 else 100)
  File "/root/Transformotion/trainers/../utils/metrics.py", line 96, in calculate_diversity
    assert activation.shape[0] > diversity_times
AssertionError
motion motion_ids ========================+> tensor([[ 165,   73, 1005,  234, 1003,  590,  182,  373,  179,  542,  549,   99,
          801,  390,  908,  134,  541,  193,   98,  368,  976,  962,  678,  241,
          517,  915,  706,  189,  987,  118,  577,  939, 1017,  909,   30, 1019,
         1008,  899,  315,  796,  575,  343,  911,  801,  871,  821,  231,  101,
          992,  646,  211,  234,  274,  966,  304,  951,  175,  557,  434,    5,
          813,  861,   32,  237,  745,  852,  325,  172,  285,  555,  299,  598,
          653,  438,  211,  854,  356,  513, 1019,  642,  420,  231,  686,  190,
          705,  557,  753, 1013,  271,  555,  801,  626,  343,  390,  542,  733,
          393,  648,  525,  140, 1019,  154,  419,  883,  200,  378,  835,  627,
          390,  151,  408,   56,  325,   31,  706,  351,  338,  324,  113,  572,
          755,  714,  824,   89,  993,  252,  932,  851,  447,  434, 1008,  213,
          255,  629,  903,  852,  646,  646,    6,  918,  254,  996,  194,  101,
          152,  554,  409,  101,   81,  170,   43,  430,   15,  461,   43,  580,
          274,  653,  343,  871,  594,  102,  112,  104,  334,  950,  191,   84,
          385,  870,  456,  818,  335,  154,  987,   94,  210,  759,  918,  723,
          743,  663,  432,  151,  457,  637,  477,  570,  727,  798,  469,  477,
          828,  617,  460,  441]], device='cuda:0')
 labels====> tensor([[735,  64, 463, 463, 874, 874, 286, 874, 463, 613, 813, 813, 813,   0,
           0, 512, 512, 512, 546, 959, 484, 484,  30,  30, 610, 380, 610, 380,
         797, 797, 797, 797, 797, 959, 546, 484, 329, 967, 505, 505, 512, 512,
         512, 512, 675, 675, 915, 959, 116, 888, 116,  30, 116, 790, 790, 942,
         790, 942, 942, 942, 942, 942,  79,  79, 793, 793, 679, 679, 652, 679,
         696, 652, 652, 652, 652, 652, 655, 891, 655, 655, 655, 908, 908, 908,
         204, 204, 204, 204, 204, 204, 204, 204, 204, 282, 282, 282, 282, 815,
         845, 845, 845, 812, 812, 602, 658, 602, 742, 742, 645, 645, 645, 645,
         645, 543, 866, 866, 645, 658, 658, 329, 658, 812, 161, 812, 812, 812,
         812, 812, 812, 658, 658, 658,  30, 866, 352, 866, 543, 543, 352, 543,
         352, 543, 553, 976,  59, 985, 985, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996,
         996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996, 996]],
       device='cuda:0')
pred_pose_eval===>torch.Size([3, 196, 263])